{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = t2.head(100000)\n",
    "features = [x for x in t.columns if (x.find('feature') >= 0)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ss.norm.rvs( loc=0, scale=1, size=(paths,len(t)-1) )[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of looping through each row maybe use this as a activation funcion?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create x*w + b\n",
    "class dense_layer():\n",
    "    def __init__(self, n_input, n_neuron):\n",
    "        self.neuron = n_neuron\n",
    "        self.weight = 0.10 * np.zeros((n_input, n_neuron))\n",
    "        self.bias = np.zeros((1, n_neuron))\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        self.output = np.dot(inputs, self.weight) + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OU_Activation():\n",
    "    def SSR(actual, pred):\n",
    "        ssr = np.sum(actual - pred)**2\n",
    "        return ssr\n",
    "\n",
    "    def ou_process(self, X, paths = 130, date_steps=16, kappa = 5, theta = -0.5, sigma = 0.5):\n",
    "        N = len(X)\n",
    "        self.n = N\n",
    "        T_vec, dt = np.linspace(0, date_steps, N, retstep=True ) # Used for creating values that evenly spaced \n",
    "        \n",
    "        self.t = theta\n",
    "        self.k = kappa\n",
    "        self.s = sigma\n",
    "        self.dt = dt\n",
    "        \n",
    "        std_asy = np.sqrt( sigma**2 /(2*self.k) )   # asymptotic standard deviation\n",
    "        self.W = ss.norm.rvs( loc=0, scale=1, size=(paths,N) )\n",
    "\n",
    "\n",
    "        y_pred = []\n",
    "        std_dt = np.sqrt( sigma**2 /(2*self.k) * (1-np.exp(-2*self.k*dt)) )\n",
    "        for t in range(0,N):\n",
    "            p = theta + np.exp(-self.k*dt) * (X[t]-theta) + std_dt * self.W[:,t]\n",
    "            y_pred.append(p)\n",
    "        y_pred = pd.DataFrame(y_pred)\n",
    "\n",
    "        # Finding the minimum SSR\n",
    "#         min_ssr = []\n",
    "#         for i in range(len(y_pred.columns)):\n",
    "#             ssr = SSR(y1, y_pred[i])\n",
    "#             min_ssr.append(ssr)\n",
    "#         min_ssr = pd.DataFrame(min_ssr)\n",
    "#         min_ssr = min_ssr[min_ssr[0] == min_ssr[0].min()]\n",
    "\n",
    "#         y_pred_final = []\n",
    "#         # Filtering to the best fit\n",
    "#         for i in range(0, N-1):\n",
    "#             p = theta + np.exp(-self.k*dt) * (X[i]-theta) + std_dt * self.W[:, min_ssr.index[0]]\n",
    "#             y_pred_final.append(p)\n",
    "#         self.W = self.W[:, min_ssr.index[0]]\n",
    "        \n",
    "        return pd.DataFrame(y_pred)\n",
    "\n",
    "#     def back_SSR(acutal, y_pred):\n",
    "#         dssr = np.sum(-2(actual-pred))\n",
    "#         return dssr\n",
    "\n",
    "#     def backward_ou_process(theta, kappa, sigma):\n",
    "#         ex = np.exp(-kappa*dt)\n",
    "#         diff_ex = 1-ex\n",
    "#         dthet = 1 + ex\n",
    "#         dkappa = -dt * (X-theta) * ex + (W * np.abs(sigma)) * ( ( (2*dt*ex)/X) / (2**(3/2) * np.sqrt(diff_ex/X) ) )\n",
    "#         dsgima = W * np.sqrt(diff_ex / X)\n",
    "        \n",
    "#     def backward_ou_process(kappa, dt):\n",
    "#         dou = np.exp(-kappa * dt)\n",
    "        \n",
    "    \n",
    "    \n",
    "    def backwards(self, weights, a, p, bias, inputs, lr=.01):\n",
    "        dou = np.exp(-self.k * self.dt)\n",
    "        diff_ex = 1-dou\n",
    "        #dW = np.sum(np.sum(-2*( a-p ) ) * np.sqrt( self.s**2 /(2*self.k) * (1-np.exp(-2*self.k*self.dt)) ))\n",
    "        ou_and_bias = np.sum( np.sum(-2*(a-p)) * dou )\n",
    "        dWeights = np.sum( np.sum(-2*(a-p)) * dou * inputs )\n",
    "\n",
    "        dthet = np.sum(np.sum(-2*(a-p)) * (1 + dou))\n",
    "        dsigma = np.sum(np.sum(-2*(a-p)) * ( (self.W.T * np.sqrt(diff_ex / inputs) * self.s) / (2 /np.abs(self.s) )) )\n",
    "        \n",
    "        dWeights = pd.DataFrame(dWeights).reset_index()\n",
    "        dWeights = dWeights[[x for x in dWeights.columns if x != 'index']]\n",
    "        for i in range(1,d.neuron):\n",
    "            dWeights[i] = dWeights[0]\n",
    "        \n",
    "        #self.new_dW = self.W - (dW * lr)\n",
    "        self.new_weights = pd.DataFrame(weights) - (dWeights * lr)\n",
    "        self.new_bias = bias - (ou_and_bias * lr)\n",
    "        self.new_theta = self.t - (dthet * lr)\n",
    "        # self.new_kappa = self.k - (dkappa * lr)\n",
    "        self.new_sigma = self.s - (dsigma * lr)\n",
    "        del dWeights\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y1 = t['resp']\n",
    "t = t[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in t.columns:\n",
    "    t[i] = t[i].fillna(t[i].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kenny\\.jupyter\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:68: RuntimeWarning: invalid value encountered in sqrt\n"
     ]
    }
   ],
   "source": [
    "ou = OU_Activation()\n",
    "\n",
    "d = dense_layer(130,130)\n",
    "d.forward(t)\n",
    "SDE = ou.ou_process(d.output)\n",
    "\n",
    "b = ou.backwards(weights=d.weight, a=y1,p=SDE[0], bias=d.bias, inputs=t)\n",
    "output = np.dot(t, ou.new_weights) + ou.new_bias\n",
    "y_pred = []\n",
    "\n",
    "std_dt = np.sqrt( ou.new_sigma**2 /(2*ou.k) * (1-np.exp(-2*ou.k*ou.dt)) )\n",
    "for t in range(0,ou.n):\n",
    "    p = ou.new_theta + np.exp(-ou.k*ou.dt) * (output[t]-ou.new_theta) + std_dt * ou.W[:, t]\n",
    "    y_pred.append(p)\n",
    "#y_pred = pd.DataFrame(y_pred)\n",
    "\n",
    "new_weights = ou.new_weights\n",
    "new_bias = ou.new_bias\n",
    "new_theta = ou.new_theta\n",
    "new_sigma = ou.new_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    print(i)\n",
    "    dou = np.exp(-ou.k * ou.dt)\n",
    "    diff_ex = 1-dou\n",
    "    #dW = np.sum(np.sum(-2*( a-p ) ) * np.sqrt( self.s**2 /(2*self.k) * (1-np.exp(-2*self.k*self.dt)) ))\n",
    "    ou_and_bias = np.sum( np.sum(-2*(y1-y_pred['feature_0'])) * dou )\n",
    "    dWeights = np.sum( np.sum(-2*(y1-y_pred['feature_0'])) * dou * t )\n",
    "\n",
    "    dthet = np.sum(np.sum(-2*(y1-y_pred['feature_0'])) * (1 + dou))\n",
    "    dsigma = np.sum( np.sum(-2*(y1-y_pred['feature_0'])) * ((ou.W.T * np.sqrt(diff_ex / t) * new_sigma) / (2 /np.abs(new_sigma) ) ))\n",
    "\n",
    "    dWeights = pd.DataFrame(dWeights).reset_index()\n",
    "    dWeights = dWeights[[x for x in dWeights.columns if x != 'index']]\n",
    "    for i in range(1,d.neuron):\n",
    "        dWeights[i] = dWeights[0]\n",
    "\n",
    "    #self.new_dW = self.W - (dW * lr)\n",
    "    new_weights = new_weights - (dWeights * lr)\n",
    "    new_bias = new_bias - (ou_and_bias * lr)\n",
    "    new_theta = new_theta - (dthet * lr)\n",
    "    new_sigma = new_sigma - (dsigma * lr)\n",
    "    \n",
    "    output = np.dot(t, ou.new_weights) + ou.new_bias\n",
    "    y_pred = []\n",
    "\n",
    "    std_dt = np.sqrt( ou.new_sigma**2 /(2*ou.k) * (1-np.exp(-2*ou.k*ou.dt)) )\n",
    "    for t in range(0,ou.n):\n",
    "        p = new_theta + np.exp(-ou.k*ou.dt) * (output[t]-new_theta) + std_dt * ou.W[:, t]\n",
    "        y_pred.append(p)\n",
    "    y_pred = pd.DataFrame(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'iloc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-940d8f4e2524>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'iloc'"
     ]
    }
   ],
   "source": [
    "y_pred.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_pred['feature_0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ou.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install tensorflow==1.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
