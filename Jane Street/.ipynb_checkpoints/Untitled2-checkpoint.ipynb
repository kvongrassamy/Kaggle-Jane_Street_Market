{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class LTCCell(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        wiring,\n",
    "        in_features=None,\n",
    "        input_mapping=\"affine\",\n",
    "        output_mapping=\"affine\",\n",
    "        ode_unfolds=6,\n",
    "        epsilon=1e-8,\n",
    "    ):\n",
    "        super(LTCCell, self).__init__()\n",
    "        if in_features is not None:\n",
    "            wiring.build((None, in_features))\n",
    "        if not wiring.is_built():\n",
    "            raise ValueError(\n",
    "                \"Wiring error! Unknown number of input features. Please pass the parameter 'in_features' or call the 'wiring.build()'.\"\n",
    "            )\n",
    "        self._init_ranges = {\n",
    "            \"gleak\": (0.001, 1.0),\n",
    "            \"vleak\": (-0.2, 0.2),\n",
    "            \"cm\": (0.4, 0.6),\n",
    "            \"w\": (0.001, 1.0),\n",
    "            \"sigma\": (3, 8),\n",
    "            \"mu\": (0.3, 0.8),\n",
    "            \"sensory_w\": (0.001, 1.0),\n",
    "            \"sensory_sigma\": (3, 8),\n",
    "            \"sensory_mu\": (0.3, 0.8),\n",
    "        }\n",
    "        self._wiring = wiring\n",
    "        self._input_mapping = input_mapping\n",
    "        self._output_mapping = output_mapping\n",
    "        self._ode_unfolds = ode_unfolds\n",
    "        self._epsilon = epsilon\n",
    "        self._allocate_parameters()\n",
    "\n",
    "    @property\n",
    "    def state_size(self):\n",
    "        return self._wiring.units\n",
    "\n",
    "    @property\n",
    "    def sensory_size(self):\n",
    "        return self._wiring.input_dim\n",
    "\n",
    "    @property\n",
    "    def motor_size(self):\n",
    "        return self._wiring.output_dim\n",
    "\n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return self.motor_size\n",
    "\n",
    "    @property\n",
    "    def synapse_count(self):\n",
    "        return np.sum(np.abs(self._wiring.adjacency_matrix))\n",
    "\n",
    "    @property\n",
    "    def sensory_synapse_count(self):\n",
    "        return np.sum(np.abs(self._wiring.adjacency_matrix))\n",
    "\n",
    "    def add_weight(self, name, init_value):\n",
    "        param = torch.nn.Parameter(init_value)\n",
    "        self.register_parameter(name, param)\n",
    "        return param\n",
    "\n",
    "    def _get_init_value(self, shape, param_name):\n",
    "        minval, maxval = self._init_ranges[param_name]\n",
    "        if minval == maxval:\n",
    "            return torch.ones(shape) * minval\n",
    "        else:\n",
    "            return torch.rand(*shape) * (maxval - minval) + minval\n",
    "\n",
    "    def _allocate_parameters(self):\n",
    "        print(\"alloc!\")\n",
    "        self._params = {}\n",
    "        self._params[\"gleak\"] = self.add_weight(\n",
    "            name=\"gleak\", init_value=self._get_init_value((self.state_size,), \"gleak\")\n",
    "        )\n",
    "        self._params[\"vleak\"] = self.add_weight(\n",
    "            name=\"vleak\", init_value=self._get_init_value((self.state_size,), \"vleak\")\n",
    "        )\n",
    "        self._params[\"cm\"] = self.add_weight(\n",
    "            name=\"cm\", init_value=self._get_init_value((self.state_size,), \"cm\")\n",
    "        )\n",
    "        self._params[\"sigma\"] = self.add_weight(\n",
    "            name=\"sigma\",\n",
    "            init_value=self._get_init_value(\n",
    "                (self.state_size, self.state_size), \"sigma\"\n",
    "            ),\n",
    "        )\n",
    "        self._params[\"mu\"] = self.add_weight(\n",
    "            name=\"mu\",\n",
    "            init_value=self._get_init_value((self.state_size, self.state_size), \"mu\"),\n",
    "        )\n",
    "        self._params[\"w\"] = self.add_weight(\n",
    "            name=\"w\",\n",
    "            init_value=self._get_init_value((self.state_size, self.state_size), \"w\"),\n",
    "        )\n",
    "        self._params[\"erev\"] = self.add_weight(\n",
    "            name=\"erev\",\n",
    "            init_value=torch.Tensor(self._wiring.erev_initializer()),\n",
    "        )\n",
    "        self._params[\"sensory_sigma\"] = self.add_weight(\n",
    "            name=\"sensory_sigma\",\n",
    "            init_value=self._get_init_value(\n",
    "                (self.sensory_size, self.state_size), \"sensory_sigma\"\n",
    "            ),\n",
    "        )\n",
    "        self._params[\"sensory_mu\"] = self.add_weight(\n",
    "            name=\"sensory_mu\",\n",
    "            init_value=self._get_init_value(\n",
    "                (self.sensory_size, self.state_size), \"sensory_mu\"\n",
    "            ),\n",
    "        )\n",
    "        self._params[\"sensory_w\"] = self.add_weight(\n",
    "            name=\"sensory_w\",\n",
    "            init_value=self._get_init_value(\n",
    "                (self.sensory_size, self.state_size), \"sensory_w\"\n",
    "            ),\n",
    "        )\n",
    "        self._params[\"sensory_erev\"] = self.add_weight(\n",
    "            name=\"sensory_erev\",\n",
    "            init_value=torch.Tensor(self._wiring.sensory_erev_initializer()),\n",
    "        )\n",
    "\n",
    "        self._params[\"sparsity_mask\"] = torch.Tensor(\n",
    "            np.abs(self._wiring.adjacency_matrix)\n",
    "        )\n",
    "        self._params[\"sensory_sparsity_mask\"] = torch.Tensor(\n",
    "            np.abs(self._wiring.sensory_adjacency_matrix)\n",
    "        )\n",
    "\n",
    "        if self._input_mapping in [\"affine\", \"linear\"]:\n",
    "            self._params[\"input_w\"] = self.add_weight(\n",
    "                name=\"input_w\",\n",
    "                init_value=torch.ones((self.sensory_size,)),\n",
    "            )\n",
    "        if self._input_mapping == \"affine\":\n",
    "            self._params[\"input_b\"] = self.add_weight(\n",
    "                name=\"input_b\",\n",
    "                init_value=torch.zeros((self.sensory_size,)),\n",
    "            )\n",
    "\n",
    "        if self._output_mapping in [\"affine\", \"linear\"]:\n",
    "            self._params[\"output_w\"] = self.add_weight(\n",
    "                name=\"output_w\",\n",
    "                init_value=torch.ones((self.motor_size,)),\n",
    "            )\n",
    "        if self._output_mapping == \"affine\":\n",
    "            self._params[\"output_b\"] = self.add_weight(\n",
    "                name=\"output_b\",\n",
    "                init_value=torch.zeros((self.motor_size,)),\n",
    "            )\n",
    "\n",
    "    def _sigmoid(self, v_pre, mu, sigma):\n",
    "        v_pre = torch.unsqueeze(v_pre, -1)  # For broadcasting\n",
    "        mues = v_pre - mu\n",
    "        x = sigma * mues\n",
    "        return torch.sigmoid(x)\n",
    "\n",
    "    def _ode_solver(self, inputs, state, elapsed_time):\n",
    "        v_pre = state\n",
    "\n",
    "        # We can pre-compute the effects of the sensory neurons here\n",
    "        sensory_w_activation = self._params[\"sensory_w\"] * self._sigmoid(\n",
    "            inputs, self._params[\"sensory_mu\"], self._params[\"sensory_sigma\"]\n",
    "        )\n",
    "        sensory_w_activation *= self._params[\"sensory_sparsity_mask\"]\n",
    "\n",
    "        sensory_rev_activation = sensory_w_activation * self._params[\"sensory_erev\"]\n",
    "\n",
    "        # Reduce over dimension 1 (=source sensory neurons)\n",
    "        w_numerator_sensory = torch.sum(sensory_rev_activation, dim=1)\n",
    "        w_denominator_sensory = torch.sum(sensory_w_activation, dim=1)\n",
    "\n",
    "        # cm/t is loop invariant\n",
    "        cm_t = self._params[\"cm\"] / (elapsed_time / self._ode_unfolds)\n",
    "\n",
    "        # Unfold the multiply ODE multiple times into one RNN step\n",
    "        for t in range(self._ode_unfolds):\n",
    "            w_activation = self._params[\"w\"] * self._sigmoid(\n",
    "                v_pre, self._params[\"mu\"], self._params[\"sigma\"]\n",
    "            )\n",
    "\n",
    "            w_activation *= self._params[\"sparsity_mask\"]\n",
    "\n",
    "            rev_activation = w_activation * self._params[\"erev\"]\n",
    "\n",
    "            # Reduce over dimension 1 (=source neurons)\n",
    "            w_numerator = torch.sum(rev_activation, dim=1) + w_numerator_sensory\n",
    "            w_denominator = torch.sum(w_activation, dim=1) + w_denominator_sensory\n",
    "\n",
    "            numerator = (\n",
    "                cm_t * v_pre\n",
    "                + self._params[\"gleak\"] * self._params[\"vleak\"]\n",
    "                + w_numerator\n",
    "            )\n",
    "            denominator = cm_t + self._params[\"gleak\"] + w_denominator\n",
    "\n",
    "            # Avoid dividing by 0\n",
    "            v_pre = numerator / (denominator + self._epsilon)\n",
    "\n",
    "        return v_pre\n",
    "\n",
    "    def _map_inputs(self, inputs):\n",
    "        if self._input_mapping in [\"affine\", \"linear\"]:\n",
    "            inputs = inputs * self._params[\"input_w\"]\n",
    "        if self._input_mapping == \"affine\":\n",
    "            inputs = inputs + self._params[\"input_b\"]\n",
    "        return inputs\n",
    "\n",
    "    def _map_outputs(self, state):\n",
    "        output = state\n",
    "        if self.motor_size < self.state_size:\n",
    "            output = output[:, 0 : self.motor_size]  # slice\n",
    "\n",
    "        if self._output_mapping in [\"affine\", \"linear\"]:\n",
    "            output = output * self._params[\"output_w\"]\n",
    "        if self._output_mapping == \"affine\":\n",
    "            output = output + self._params[\"output_b\"]\n",
    "        return output\n",
    "\n",
    "    def _clip(self, w):\n",
    "        return torch.nn.ReLU()(w)\n",
    "\n",
    "    def apply_weight_constraints(self):\n",
    "        self._params[\"w\"].data = self._clip(self._params[\"w\"].data)\n",
    "        self._params[\"sensory_w\"].data = self._clip(self._params[\"sensory_w\"].data)\n",
    "        self._params[\"cm\"].data = self._clip(self._params[\"cm\"].data)\n",
    "        self._params[\"gleak\"].data = self._clip(self._params[\"gleak\"].data)\n",
    "\n",
    "    def forward(self, inputs, states):\n",
    "        # Regularly sampled mode (elapsed time = 1 second)\n",
    "        elapsed_time = 1.0\n",
    "        inputs = self._map_inputs(inputs)\n",
    "\n",
    "        next_state = self._ode_solver(inputs, states, elapsed_time)\n",
    "\n",
    "        outputs = self._map_outputs(next_state)\n",
    "\n",
    "        return outputs, next_state\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Wiring:\n",
    "    def __init__(self, units):\n",
    "        self.units = units\n",
    "        self.adjacency_matrix = np.zeros([units, units], dtype=np.int32)\n",
    "        self.input_dim = None\n",
    "        self.output_dim = None\n",
    "\n",
    "    def is_built(self):\n",
    "        return self.input_dim is not None\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        input_dim = int(input_shape[1])\n",
    "        if not self.input_dim is None and self.input_dim != input_dim:\n",
    "            raise ValueError(\n",
    "                \"Conflicting input dimensions provided. set_input_dim() was called with {} but actual input has dimension {}\".format(\n",
    "                    self.input_dim, input_dim\n",
    "                )\n",
    "            )\n",
    "        if self.input_dim is None:\n",
    "            self.set_input_dim(input_dim)\n",
    "\n",
    "    def erev_initializer(self, shape=None, dtype=None):\n",
    "        return np.copy(self.adjacency_matrix)\n",
    "\n",
    "    def sensory_erev_initializer(self, shape=None, dtype=None):\n",
    "        return np.copy(self.sensory_adjacency_matrix)\n",
    "\n",
    "    def set_input_dim(self, input_dim):\n",
    "        self.input_dim = input_dim\n",
    "        self.sensory_adjacency_matrix = np.zeros(\n",
    "            [input_dim, self.units], dtype=np.int32\n",
    "        )\n",
    "\n",
    "    def set_output_dim(self, output_dim):\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "    # May be overwritten by child class\n",
    "    def get_type_of_neuron(self, neuron_id):\n",
    "        return \"motor\" if neuron_id < self.output_dim else \"inter\"\n",
    "\n",
    "    def add_synapse(self, src, dest, polarity):\n",
    "        if src < 0 or src >= self.units:\n",
    "            raise ValueError(\n",
    "                \"Cannot add synapse originating in {} if cell has only {} units\".format(\n",
    "                    src, self.units\n",
    "                )\n",
    "            )\n",
    "        if dest < 0 or dest >= self.units:\n",
    "            raise ValueError(\n",
    "                \"Cannot add synapse feeding into {} if cell has only {} units\".format(\n",
    "                    dest, self.units\n",
    "                )\n",
    "            )\n",
    "        if not polarity in [-1, 1]:\n",
    "            raise ValueError(\n",
    "                \"Cannot add synapse with polarity {} (expected -1 or +1)\".format(\n",
    "                    polarity\n",
    "                )\n",
    "            )\n",
    "        self.adjacency_matrix[src, dest] = polarity\n",
    "\n",
    "    def add_sensory_synapse(self, src, dest, polarity):\n",
    "        if self.input_dim is None:\n",
    "            raise ValueError(\n",
    "                \"Cannot add sensory synapses before build() has been called!\"\n",
    "            )\n",
    "        if src < 0 or src >= self.input_dim:\n",
    "            raise ValueError(\n",
    "                \"Cannot add sensory synapse originating in {} if input has only {} features\".format(\n",
    "                    src, self.input_dim\n",
    "                )\n",
    "            )\n",
    "        if dest < 0 or dest >= self.units:\n",
    "            raise ValueError(\n",
    "                \"Cannot add synapse feeding into {} if cell has only {} units\".format(\n",
    "                    dest, self.units\n",
    "                )\n",
    "            )\n",
    "        if not polarity in [-1, 1]:\n",
    "            raise ValueError(\n",
    "                \"Cannot add synapse with polarity {} (expected -1 or +1)\".format(\n",
    "                    polarity\n",
    "                )\n",
    "            )\n",
    "        self.sensory_adjacency_matrix[src, dest] = polarity\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\n",
    "            \"adjacency_matrix\": self.adjacency_matrix,\n",
    "            \"sensory_adjacency_matrix\": self.sensory_adjacency_matrix,\n",
    "            \"input_dim\": self.input_dim,\n",
    "            \"output_dim\": self.output_dim,\n",
    "            \"units\": self.units,\n",
    "        }\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        # There might be a cleaner solution but it will work\n",
    "        wiring = Wiring(config[\"units\"])\n",
    "        wiring.adjacency_matrix = config[\"adjacency_matrix\"]\n",
    "        wiring.sensory_adjacency_matrix = config[\"sensory_adjacency_matrix\"]\n",
    "        wiring.input_dim = config[\"input_dim\"]\n",
    "        wiring.output_dim = config[\"output_dim\"]\n",
    "\n",
    "        return wiring\n",
    "\n",
    "\n",
    "class FullyConnected(Wiring):\n",
    "    def __init__(\n",
    "        self, units, output_dim=None, erev_init_seed=1111, self_connections=True\n",
    "    ):\n",
    "        super(FullyConnected, self).__init__(units)\n",
    "        if output_dim is None:\n",
    "            output_dim = units\n",
    "        self.self_connections = self_connections\n",
    "        self.set_output_dim(output_dim)\n",
    "        self._rng = np.random.default_rng(erev_init_seed)\n",
    "        for src in range(self.units):\n",
    "            for dest in range(self.units):\n",
    "                if src == dest and not self_connections:\n",
    "                    continue\n",
    "                polarity = self._rng.choice([-1, 1, 1])\n",
    "                self.add_synapse(src, dest, polarity)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super().build(input_shape)\n",
    "        for src in range(self.input_dim):\n",
    "            for dest in range(self.units):\n",
    "                polarity = self._rng.choice([-1, 1, 1])\n",
    "                self.add_sensory_synapse(src, dest, polarity)\n",
    "\n",
    "\n",
    "class Random(Wiring):\n",
    "    def __init__(self, units, output_dim=None, sparsity_level=0.0, random_seed=1111):\n",
    "        super(Random, self).__init__(units)\n",
    "        if output_dim is None:\n",
    "            output_dim = units\n",
    "        self.set_output_dim(output_dim)\n",
    "        self.sparsity_level = sparsity_level\n",
    "\n",
    "        if sparsity_level < 0.0 or sparsity_level >= 1.0:\n",
    "            raise ValueError(\n",
    "                \"Invalid sparsity level '{}', expected value in range [0,1)\".format(\n",
    "                    sparsity_level\n",
    "                )\n",
    "            )\n",
    "        self._rng = np.random.default_rng(random_seed)\n",
    "\n",
    "        number_of_synapses = int(np.round(units * units * (1 - sparsity_level)))\n",
    "        all_synapses = []\n",
    "        for src in range(self.units):\n",
    "            for dest in range(self.units):\n",
    "                all_synapses.append((src, dest))\n",
    "\n",
    "        used_synapses = self._rng.choice(\n",
    "            all_synapses, size=number_of_synapses, replace=False\n",
    "        )\n",
    "        for src, dest in used_synapses:\n",
    "            polarity = self._rng.choice([-1, 1, 1])\n",
    "            self.add_synapse(src, dest, polarity)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super().build(input_shape)\n",
    "        number_of_sensory_synapses = int(\n",
    "            np.round(self.input_dim * self.units * (1 - self.sparsity_level))\n",
    "        )\n",
    "        all_sensory_synapses = []\n",
    "        for src in range(self.input_dim):\n",
    "            for dest in range(self.units):\n",
    "                all_sensory_synapses.append((src, dest))\n",
    "\n",
    "        used_sensory_synapses = self._rng.choice(\n",
    "            all_sensory_synapses, size=number_of_sensory_synapses, replace=False\n",
    "        )\n",
    "        for src, dest in used_sensory_synapses:\n",
    "            polarity = self._rng.choice([-1, 1, 1])\n",
    "            self.add_sensory_synapse(src, dest, polarity)\n",
    "            polarity = self._rng.choice([-1, 1, 1])\n",
    "            self.add_sensory_synapse(src, dest, polarity)\n",
    "\n",
    "\n",
    "class NCP(Wiring):\n",
    "    def __init__(\n",
    "        self,\n",
    "        inter_neurons,\n",
    "        command_neurons,\n",
    "        motor_neurons,\n",
    "        sensory_fanout,\n",
    "        inter_fanout,\n",
    "        recurrent_command_synapses,\n",
    "        motor_fanin,\n",
    "        seed=22222,\n",
    "    ):\n",
    "\n",
    "        super(NCP, self).__init__(inter_neurons + command_neurons + motor_neurons)\n",
    "        self.set_output_dim(motor_neurons)\n",
    "        self._rng = np.random.RandomState(seed)\n",
    "        self._num_inter_neurons = inter_neurons\n",
    "        self._num_command_neurons = command_neurons\n",
    "        self._num_motor_neurons = motor_neurons\n",
    "        self._sensory_fanout = sensory_fanout\n",
    "        self._inter_fanout = inter_fanout\n",
    "        self._recurrent_command_synapses = recurrent_command_synapses\n",
    "        self._motor_fanin = motor_fanin\n",
    "\n",
    "        # Neuron IDs: [0..motor ... command ... inter]\n",
    "        self._motor_neurons = list(range(0, self._num_motor_neurons))\n",
    "        self._command_neurons = list(\n",
    "            range(\n",
    "                self._num_motor_neurons,\n",
    "                self._num_motor_neurons + self._num_command_neurons,\n",
    "            )\n",
    "        )\n",
    "        self._inter_neurons = list(\n",
    "            range(\n",
    "                self._num_motor_neurons + self._num_command_neurons,\n",
    "                self._num_motor_neurons\n",
    "                + self._num_command_neurons\n",
    "                + self._num_inter_neurons,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        if self._motor_fanin > self._num_command_neurons:\n",
    "            raise ValueError(\n",
    "                \"Error: Motor fanin parameter is {} but there are only {} command neurons\".format(\n",
    "                    self._motor_fanin, self._num_command_neurons\n",
    "                )\n",
    "            )\n",
    "        if self._sensory_fanout > self._num_inter_neurons:\n",
    "            raise ValueError(\n",
    "                \"Error: Sensory fanout parameter is {} but there are only {} inter neurons\".format(\n",
    "                    self._sensory_fanout, self._num_inter_neurons\n",
    "                )\n",
    "            )\n",
    "        if self._inter_fanout > self._num_command_neurons:\n",
    "            raise ValueError(\n",
    "                \"Error:: Inter fanout parameter is {} but there are only {} command neurons\".format(\n",
    "                    self._inter_fanout, self._num_command_neurons\n",
    "                )\n",
    "            )\n",
    "\n",
    "    def get_type_of_neuron(self, neuron_id):\n",
    "        if neuron_id < self._num_motor_neurons:\n",
    "            return \"motor\"\n",
    "        if neuron_id < self._num_motor_neurons + self._num_command_neurons:\n",
    "            return \"command\"\n",
    "        return \"inter\"\n",
    "\n",
    "    def _build_sensory_to_inter_layer(self):\n",
    "        unreachable_inter_neurons = [l for l in self._inter_neurons]\n",
    "        # Randomly connects each sensory neuron to exactly _sensory_fanout number of interneurons\n",
    "        for src in self._sensory_neurons:\n",
    "            for dest in self._rng.choice(\n",
    "                self._inter_neurons, size=self._sensory_fanout, replace=False\n",
    "            ):\n",
    "                if dest in unreachable_inter_neurons:\n",
    "                    unreachable_inter_neurons.remove(dest)\n",
    "                polarity = self._rng.choice([-1, 1])\n",
    "                self.add_sensory_synapse(src, dest, polarity)\n",
    "\n",
    "        # If it happens that some interneurons are not connected, connect them now\n",
    "        mean_inter_neuron_fanin = int(\n",
    "            self._num_sensory_neurons * self._sensory_fanout / self._num_inter_neurons\n",
    "        )\n",
    "        # Connect \"forgotten\" inter neuron by at least 1 and at most all sensory neuron\n",
    "        mean_inter_neuron_fanin = np.clip(\n",
    "            mean_inter_neuron_fanin, 1, self._num_sensory_neurons\n",
    "        )\n",
    "        for dest in unreachable_inter_neurons:\n",
    "            for src in self._rng.choice(\n",
    "                self._sensory_neurons, size=mean_inter_neuron_fanin, replace=False\n",
    "            ):\n",
    "                polarity = self._rng.choice([-1, 1])\n",
    "                self.add_sensory_synapse(src, dest, polarity)\n",
    "\n",
    "    def _build_inter_to_command_layer(self):\n",
    "        # Randomly connect interneurons to command neurons\n",
    "        unreachable_command_neurons = [l for l in self._command_neurons]\n",
    "        for src in self._inter_neurons:\n",
    "            for dest in self._rng.choice(\n",
    "                self._command_neurons, size=self._inter_fanout, replace=False\n",
    "            ):\n",
    "                if dest in unreachable_command_neurons:\n",
    "                    unreachable_command_neurons.remove(dest)\n",
    "                polarity = self._rng.choice([-1, 1])\n",
    "                self.add_synapse(src, dest, polarity)\n",
    "\n",
    "        # If it happens that some command neurons are not connected, connect them now\n",
    "        mean_command_neurons_fanin = int(\n",
    "            self._num_inter_neurons * self._inter_fanout / self._num_command_neurons\n",
    "        )\n",
    "        # Connect \"forgotten\" command neuron by at least 1 and at most all inter neuron\n",
    "        mean_command_neurons_fanin = np.clip(\n",
    "            mean_command_neurons_fanin, 1, self._num_command_neurons\n",
    "        )\n",
    "        for dest in unreachable_command_neurons:\n",
    "            for src in self._rng.choice(\n",
    "                self._inter_neurons, size=mean_command_neurons_fanin, replace=False\n",
    "            ):\n",
    "                polarity = self._rng.choice([-1, 1])\n",
    "                self.add_synapse(src, dest, polarity)\n",
    "\n",
    "    def _build_recurrent_command_layer(self):\n",
    "        # Add recurrency in command neurons\n",
    "        for i in range(self._recurrent_command_synapses):\n",
    "            src = self._rng.choice(self._command_neurons)\n",
    "            dest = self._rng.choice(self._command_neurons)\n",
    "            polarity = self._rng.choice([-1, 1])\n",
    "            self.add_synapse(src, dest, polarity)\n",
    "\n",
    "    def _build_command__to_motor_layer(self):\n",
    "        # Randomly connect command neurons to motor neurons\n",
    "        unreachable_command_neurons = [l for l in self._command_neurons]\n",
    "        for dest in self._motor_neurons:\n",
    "            for src in self._rng.choice(\n",
    "                self._command_neurons, size=self._motor_fanin, replace=False\n",
    "            ):\n",
    "                if src in unreachable_command_neurons:\n",
    "                    unreachable_command_neurons.remove(src)\n",
    "                polarity = self._rng.choice([-1, 1])\n",
    "                self.add_synapse(src, dest, polarity)\n",
    "\n",
    "        # If it happens that some commandneurons are not connected, connect them now\n",
    "        mean_command_fanout = int(\n",
    "            self._num_motor_neurons * self._motor_fanin / self._num_command_neurons\n",
    "        )\n",
    "        # Connect \"forgotten\" command neuron to at least 1 and at most all motor neuron\n",
    "        mean_command_fanout = np.clip(mean_command_fanout, 1, self._num_motor_neurons)\n",
    "        for src in unreachable_command_neurons:\n",
    "            for dest in self._rng.choice(\n",
    "                self._motor_neurons, size=mean_command_fanout, replace=False\n",
    "            ):\n",
    "                polarity = self._rng.choice([-1, 1])\n",
    "                self.add_synapse(src, dest, polarity)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super().build(input_shape)\n",
    "        self._num_sensory_neurons = self.input_dim\n",
    "        self._sensory_neurons = list(range(0, self._num_sensory_neurons))\n",
    "\n",
    "        self._build_sensory_to_inter_layer()\n",
    "        self._build_inter_to_command_layer()\n",
    "        self._build_recurrent_command_layer()\n",
    "        self._build_command__to_motor_layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "\n",
    "class RNNSequence(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        rnn_cell,\n",
    "    ):\n",
    "        super(RNNSequence, self).__init__()\n",
    "        self.rnn_cell = rnn_cell\n",
    "\n",
    "    def forward(self, x):\n",
    "        device = x.device\n",
    "        batch_size = x.size(0)\n",
    "        seq_len = x.size(1)\n",
    "        hidden_state = torch.zeros(\n",
    "            (batch_size, self.rnn_cell.state_size), device=device\n",
    "        )\n",
    "        outputs = []\n",
    "        for t in range(seq_len):\n",
    "            inputs = x[:, t]\n",
    "            new_output, hidden_state = self.rnn_cell.forward(inputs, hidden_state)\n",
    "            outputs.append(new_output)\n",
    "        outputs = torch.stack(outputs, dim=1)  # return entire sequence\n",
    "        return outputs\n",
    "\n",
    "# LightningModule for training a RNNSequence module\n",
    "class SequenceLearner(pl.LightningModule):\n",
    "    def __init__(self, model, lr=0.005):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.lr = lr\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.model.forward(x)\n",
    "        y_hat = y_hat.view_as(y)\n",
    "        loss = nn.MSELoss()(y_hat, y)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.model.forward(x)\n",
    "        y_hat = y_hat.view_as(y)\n",
    "        loss = nn.MSELoss()(y_hat, y)\n",
    "\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # Here we just reuse the validation_step for testing\n",
    "        return self.validation_step(batch, batch_idx)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "\n",
    "    def optimizer_step(\n",
    "        self,\n",
    "        current_epoch,\n",
    "        batch_nb,\n",
    "        optimizer,\n",
    "        optimizer_idx,\n",
    "        closure,\n",
    "        on_tpu=False,\n",
    "        using_native_amp=False,\n",
    "        using_lbfgs=False,\n",
    "    ):\n",
    "        optimizer.optimizer.step(closure=closure)\n",
    "        # Apply weight constraints\n",
    "        self.model.rnn_cell.apply_weight_constraints()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [x for x in t.columns if (x.find('feature') >= 0)]\n",
    "for i in t.columns:\n",
    "    t[i] = t[i].fillna(t[i].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# np.array(t['resp']).reshape([1, N, 1]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_y.shape:  torch.Size([1, 2390491, 1])\n"
     ]
    }
   ],
   "source": [
    "in_features = len(t[features].columns)\n",
    "out_features = 1\n",
    "N = t['ts_id'].max() + 1  # Length of the time-series\n",
    "# Input feature is a sine and a cosine wave\n",
    "data_x = np.array(t[features])\n",
    "data_x = np.expand_dims(data_x, axis=0).astype(np.float32)  # Add batch dimension\n",
    "# Target output is a sine with double the frequency of the input signal\n",
    "data_y = np.array(t['resp']).reshape([1, N, 1]).astype(np.float32)\n",
    "data_x = torch.Tensor(data_x)\n",
    "data_y = torch.Tensor(data_y)\n",
    "print(\"data_y.shape: \", str(data_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.TensorDataset at 0x1ea7d9cccf8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.TensorDataset(data_x, data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alloc!\n"
     ]
    }
   ],
   "source": [
    "wiring = FullyConnected(in_features, out_features)  # 16 units, 8 motor neurons\n",
    "ltc_cell = LTCCell(wiring, in_features)\n",
    "dataloader = data.DataLoader(\n",
    "    data.TensorDataset(data_x, data_y), batch_size=120, shuffle=True, num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2390491, 130])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: False\n",
      "TPU available: None, using: 0 TPU cores\n",
      "C:\\Users\\kenny\\.jupyter\\Anaconda\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:50: UserWarning: GPU available but not used. Set the --gpus flag when calling the script.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "C:\\Users\\kenny\\.jupyter\\Anaconda\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:50: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "  | Name  | Type        | Params\n",
      "--------------------------------------\n",
      "0 | model | RNNSequence | 135 K \n",
      "--------------------------------------\n",
      "135 K     Trainable params\n",
      "0         Non-trainable params\n",
      "135 K     Total params\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b48fc7cdad7c419fa4ecf0583964867c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ltc_sequence = RNNSequence(\n",
    "    ltc_cell,\n",
    ")\n",
    "learn = SequenceLearner(ltc_sequence, lr=0.01)\n",
    "trainer = pl.Trainer(\n",
    "    #logger=pl.loggers.CSVLogger(\"log\"),\n",
    "    max_epochs=400,\n",
    "    progress_bar_refresh_rate=1,\n",
    "    gradient_clip_val=1,  # Clip gradient to stabilize training\n",
    "    #gpus=0,\n",
    ")\n",
    "trainer.fit(learn, dataloader)\n",
    "results = trainer.test(learn, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
